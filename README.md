# Projet de Streaming de Socket en Temps Réel

Bienvenue dans le projet **`openai-streaming-pipeline`**, une initiative personnelle dédiée à la création d'un pipeline d'ingénierie de données de bout en bout. Ce projet utilise TCP/IP Socket, Apache Spark, OpenAI LLM, Kafka et Elasticsearch pour démontrer un flux de traitement de données en temps réel. Je couvre chaque étape, de l'acquisition des données au traitement, en passant par l'analyse des sentiments avec ChatGPT, la production vers un topic Kafka et la connexion à Elasticsearch.

## Objectifs du Projet

- **Acquisition des Données** : Je transfère des données via une connexion socket TCP/IP.
- **Traitement des Données** : J'utilise Apache Spark pour traiter les données en temps réel.
- **Analyse des Sentiments** : J'intègre OpenAI ChatGPT pour analyser les sentiments des données.
- **Streaming de Données** : J'utilise Apache Kafka pour le streaming et la visualisation des données.
- **Réplication de Données** : J'indexe les données traitées avec Elasticsearch.
- **Visualisation** : Je crée des visualisations des données avec Kibana et d'autres outils comme Power BI et Tableau.

## Technologies Utilisées

- **Langage de Programmation** : Python
- **Framework de Traitement de Données** : Apache Spark
- **Système de Messagerie** : Apache Kafka
- **Moteur de Recherche** : Elasticsearch
- **Outil de Visualisation** : Kibana
- **API d'Intelligence Artificielle** : OpenAI ChatGPT

## Installation et Configuration

### Prérequis

Avant de commencer, assurez-vous d'avoir installé les éléments suivants :

- Python 3.x
- Apache Spark
- Apache Kafka
- Elasticsearch
- Kibana
- OpenAI SDK

### Étapes d'Installation

1. **Cloner le dépôt :**
   ```bash
   git clone https://github.com/Santoudllo/openai-streaming-pipeline.git
   cd openai-streaming-pipeline

MIT License

Copyright (c) [2024] [santoudllo]


### Remarques
- N'hésitez pas à modifier le texte pour mieux correspondre à votre style. Si vous avez d'autres ajustements ou questions, faites-le moi savoir !
